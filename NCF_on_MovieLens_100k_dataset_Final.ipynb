{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK-5wOvhlScp"
      },
      "source": [
        "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
        "\n",
        "<i>Licensed under the MIT License.</i>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3A-HKw6kx7t"
      },
      "outputs": [],
      "source": [
        "# Install Microsoft Recommendation Libraries\n",
        "!pip install recommenders[examples]\n",
        "!pip install tf_slim\n",
        "!pip install fastai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMe6E1E4lScu"
      },
      "outputs": [],
      "source": [
        "# Import Microsoft Recommendation Libraries\n",
        "import sys\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('ERROR') # only show error messages\n",
        "\n",
        "from recommenders.utils.timer import Timer\n",
        "from recommenders.models.ncf.ncf_singlenode import NCF\n",
        "from recommenders.models.ncf.dataset import Dataset as NCFDataset\n",
        "from recommenders.datasets import movielens\n",
        "from recommenders.utils.notebook_utils import is_jupyter\n",
        "from recommenders.datasets.python_splitters import python_chrono_split\n",
        "from recommenders.evaluation.python_evaluation import (rmse, mae, rsquared, exp_var, map_at_k, ndcg_at_k, precision_at_k, \n",
        "                                                     recall_at_k, get_top_k_items)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gVUrbbEOlScw"
      },
      "outputs": [],
      "source": [
        "# Download movielens 100k dataset\n",
        "df = movielens.load_pandas_df(\n",
        "    size='100k',\n",
        "    header=[\"userID\", \"itemID\", \"rating\", \"timestamp\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfAFO0tolScx"
      },
      "outputs": [],
      "source": [
        "# Split the data into 75% training and rest testing using Spark chronological splitter\n",
        "train, test = python_chrono_split(df, 0.75)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WW5ZEmptlScx"
      },
      "outputs": [],
      "source": [
        "# Remove any users or items from the test set that aren't found in the training set.\n",
        "\n",
        "test = test[test[\"userID\"].isin(train[\"userID\"].unique())]\n",
        "test = test[test[\"itemID\"].isin(train[\"itemID\"].unique())]\n",
        "\n",
        "# Remove the timestamp column as it would not be used by the NCF model\n",
        "\n",
        "train = train.drop('timestamp', axis=1)\n",
        "test = test.drop('timestamp', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vxmc0EAilScy"
      },
      "outputs": [],
      "source": [
        "# Export the train and test files to CSV, later to be imported in NCF model\n",
        "\n",
        "train_file = \"./train.csv\"\n",
        "test_file = \"./test.csv\"\n",
        "train.to_csv(train_file, index=False)\n",
        "test.to_csv(test_file, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation of Movielens 100k Dataset using dataframe\n",
        "\n",
        "df = pd.read_csv('/content/train.csv')\n",
        "df.head()\n",
        "\n",
        "#The data consists of user and item and the corresponding ratings"
      ],
      "metadata": {
        "id": "WmojE7DNj5lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbX12xXAlScy"
      },
      "outputs": [],
      "source": [
        "# Import the train and test files using the NCFDataset function\n",
        "data = NCFDataset(train_file=train_file, test_file=test_file, seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining the parameters for the Recommendation system\n",
        "\n",
        "# Top k items to be recommended by the system\n",
        "TOP_K = 10\n",
        "\n",
        "# Parameters for the Model\n",
        "epochs = 50\n",
        "batch_size = 256\n",
        "seed = 42"
      ],
      "metadata": {
        "id": "1SsTYn1-k7qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7_U21KIlScz"
      },
      "outputs": [],
      "source": [
        "# Commented code below shows the model NCF, which will be used in the hyperparameter tuning below\n",
        "\n",
        "model = NCF (\n",
        "     n_users=data.n_users, \n",
        "    n_items=data.n_items,\n",
        "    model_type=\"NeuMF\",\n",
        "    n_factors=8,\n",
        "    layer_sizes=[32, 16,8],\n",
        "    n_epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    learning_rate=0.01,\n",
        "    verbose=10,\n",
        "    seed=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the parameters to be used for the Hyperparameter tuning of the model\n",
        "\n",
        "# param_grid = {\n",
        "#     \"n_factors\": [8, 16],\n",
        "#     \"layer_sizes\": [[32,16,8],[16,8]],\n",
        "#     \"n_epochs\": [20,50],\n",
        "#     \"learning_rate\": [0.0001, 0.001, 0.01]\n",
        "# }\n",
        "\n",
        "param_grid = {\n",
        "    \"n_factors\": [8],\n",
        "    \"layer_sizes\": [[32,16,8]],\n",
        "    \"n_epochs\": [5],\n",
        "    \"learning_rate\": [0.1]\n",
        "}\n"
      ],
      "metadata": {
        "id": "OibV7kQyAm0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use itertools library to create different combindations of the parameters and store them in the list param_combinations\n",
        "param_combinations = list(itertools.product(*param_grid.values()))\n",
        "results = []\n"
      ],
      "metadata": {
        "id": "QGt4n0K4E1A-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "metadata": {
        "id": "ZcUwzzI5p6Pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning, fit the model for each set of hyperparameters, predict the ratings and recommendations and store the metrics in the list 'results'\n",
        "\n",
        "for params in param_combinations:\n",
        "    print (params)\n",
        "    model = NCF(\n",
        "        n_users=data.n_users, \n",
        "        n_items=data.n_items,\n",
        "        model_type=\"NeuMF\",\n",
        "        n_factors=params[0],\n",
        "        layer_sizes=params[1],\n",
        "        n_epochs=params[2],\n",
        "        learning_rate=params[3],\n",
        "        verbose=10,\n",
        "        seed=seed\n",
        "        )\n",
        "    \n",
        "    model.fit(data)\n",
        "\n",
        "    users, items, preds = [], [], []\n",
        "\n",
        "    item = list(train.itemID.unique())\n",
        "    for user in train.userID.unique():\n",
        "        user = [user] * len(item) \n",
        "        users.extend(user)\n",
        "        items.extend(item)\n",
        "        preds.extend(list(model.predict(user, item, is_list=True)))\n",
        "\n",
        "    all_predictions = pd.DataFrame(data={\"userID\": users, \"itemID\":items, \"prediction\":preds})\n",
        "\n",
        "    merged = pd.merge(train, all_predictions, on=[\"userID\", \"itemID\"], how=\"inner\")\n",
        "    merged2 = pd.merge(train, all_predictions, on=[\"userID\", \"itemID\"], how=\"outer\")\n",
        "    all_predictions = merged2[merged2.rating.isnull()].drop('rating', axis=1)\n",
        "\n",
        "    # Calculating the evaluation metrics:\n",
        "    score1 = map_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
        "    score2 = ndcg_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
        "    score3 = precision_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
        "    score4 = recall_at_k(test, all_predictions, col_prediction='prediction', k=TOP_K)\n",
        "\n",
        "    # Denormalize the predicted ratings to calculate the error between the actual and predicted ratings\n",
        "    min_rating = train['rating'].min()\n",
        "    max_rating = train['rating'].max()\n",
        "\n",
        "    predicted_ratings = merged['prediction']\n",
        "    rescaled_predicted_ratings = (predicted_ratings - predicted_ratings.min()) / (predicted_ratings.max() - predicted_ratings.min())\n",
        "    rescaled_predicted_ratings = (rescaled_predicted_ratings * (max_rating - min_rating)) + min_rating\n",
        "    \n",
        "    y_true = train.rating.values\n",
        "    y_pred = rescaled_predicted_ratings.values\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "       \n",
        "    # store the results for this set of hyperparameters\n",
        "    print(\"params:\", params, \"MAP@K:\", score1, \"NDCG@K:\", score2, \"Precision@K:\", score3, \"Recall@K:\", score4, \"RMSE:\", rmse)\n",
        "    results.append({\n",
        "        \"params\": params,\n",
        "        \"MAP@K\": score1,\n",
        "        \"NDCG@K\": score2, \"Precision@K\": score3, \"Recall@K\": score4, \"RMSE\": rmse\n",
        "    })\n",
        "\n"
      ],
      "metadata": {
        "id": "xFXLY6ziFDrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the model parameter combination with the minimum RMSE\n",
        "min_entry = min(results, key=lambda x: x['RMSE'])\n",
        "print('Parametrics that gave the least error: ', min_entry)"
      ],
      "metadata": {
        "id": "6QK8I0oiLl6R"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "reco_gpu",
      "language": "python",
      "name": "conda-env-reco_gpu-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}